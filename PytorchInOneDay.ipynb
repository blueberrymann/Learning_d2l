{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Tensor?\n",
    "\n",
    "### 创建一个tensor\n",
    "\n",
    "- 常量和向量通常用小写字母来表示\n",
    "- 矩阵和张量通常用大写字母来表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个常量，值为7，0维张量\n",
    "scalar = torch.tensor(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "TENSOR = torch.tensor([[[[1, 2, 3],\n",
    "                        [4, 5, 6],\n",
    "                        [7, 8, 9]\n",
    "                        ]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 3, 3])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0][0][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建一个random tensor\n",
    "\n",
    "- 为什么要使用random tensor呢？\n",
    "- 因为许多神经网络的训练都是从random tensor开始的，随机的数能更好的表示数据\n",
    "\n",
    "`start with random numbers -> look at data -> update random numebrs -> look at data -> update random numbers -> ...`\n",
    "\n",
    "Torch.rand - https://docs.pytorch.org/docs/main/generated/torch.rand.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a random tensor of size [3, 4]\n",
    "\n",
    "random_tensor = torch.rand(3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5273, 0.3559, 0.3121, 0.6394],\n",
       "        [0.0758, 0.1926, 0.3885, 0.8590],\n",
       "        [0.7229, 0.1401, 0.0044, 0.9996]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[6.4042e-01, 1.6824e-01, 4.4650e-01, 4.6604e-01, 2.1089e-02,\n",
       "          3.6925e-01, 6.3193e-01, 7.7767e-01, 3.4610e-01, 6.8252e-01],\n",
       "         [2.7281e-01, 4.4164e-02, 6.7652e-01, 7.6465e-01, 7.9856e-01,\n",
       "          4.7576e-01, 2.7705e-01, 4.4536e-02, 4.5006e-01, 2.1996e-01],\n",
       "         [2.4056e-01, 7.8353e-01, 8.7501e-01, 1.2139e-01, 6.3964e-01,\n",
       "          4.2565e-01, 2.2357e-01, 7.4199e-01, 8.7797e-01, 1.1005e-01],\n",
       "         [7.6061e-01, 4.5481e-01, 3.6235e-01, 4.6693e-02, 4.9445e-01,\n",
       "          9.1158e-02, 6.4800e-01, 4.5538e-01, 2.7223e-01, 9.8484e-01],\n",
       "         [1.5020e-01, 9.8159e-01, 7.0798e-01, 3.8011e-01, 1.3972e-01,\n",
       "          9.8451e-01, 4.7582e-01, 4.3353e-01, 3.6383e-01, 8.3942e-01],\n",
       "         [7.9280e-01, 9.2623e-01, 2.6389e-01, 6.7390e-01, 7.8750e-01,\n",
       "          3.9002e-01, 7.2361e-02, 6.9357e-01, 4.3819e-01, 9.8108e-01],\n",
       "         [8.2142e-01, 8.1958e-01, 5.1234e-01, 5.5544e-01, 9.0010e-01,\n",
       "          6.5551e-01, 7.1931e-01, 7.7559e-01, 3.8341e-01, 5.8654e-01],\n",
       "         [1.6020e-01, 7.4139e-01, 8.2031e-01, 2.5094e-01, 5.0708e-01,\n",
       "          1.4594e-01, 2.5500e-01, 5.1309e-01, 7.3185e-01, 5.1871e-01],\n",
       "         [7.3994e-01, 1.8709e-01, 2.7697e-01, 6.7738e-01, 2.9038e-02,\n",
       "          1.5477e-01, 4.7132e-01, 6.9035e-01, 3.3987e-01, 5.1965e-01],\n",
       "         [7.4831e-02, 8.9826e-01, 3.5929e-01, 6.5979e-01, 1.3700e-01,\n",
       "          4.3297e-01, 2.9988e-01, 3.9770e-02, 9.0557e-01, 3.7490e-01]],\n",
       "\n",
       "        [[9.5175e-01, 5.3846e-01, 9.4655e-01, 8.8763e-01, 7.7125e-01,\n",
       "          6.5179e-01, 2.8505e-01, 6.3727e-01, 5.2522e-02, 9.2551e-01],\n",
       "         [7.9516e-01, 4.0821e-02, 6.2074e-01, 2.9660e-01, 7.7693e-01,\n",
       "          8.3829e-01, 4.7640e-02, 4.7993e-01, 4.3308e-01, 6.4154e-01],\n",
       "         [9.3414e-01, 3.0749e-01, 2.1878e-01, 7.0240e-01, 3.9434e-01,\n",
       "          7.1890e-01, 4.4556e-01, 5.7180e-01, 5.3260e-01, 4.8423e-02],\n",
       "         [3.7757e-01, 4.3637e-01, 3.7361e-01, 9.9551e-01, 4.2308e-01,\n",
       "          3.5188e-01, 9.8675e-01, 8.3191e-01, 8.9214e-01, 9.2312e-01],\n",
       "         [3.2672e-01, 8.5615e-01, 5.2743e-01, 6.5852e-01, 1.2058e-01,\n",
       "          1.0782e-01, 1.0788e-02, 3.8422e-01, 3.3866e-01, 2.9732e-02],\n",
       "         [4.4546e-01, 3.2861e-01, 4.4510e-01, 7.8698e-01, 7.4556e-01,\n",
       "          3.0894e-01, 8.6394e-02, 2.4486e-01, 7.5201e-01, 6.0774e-01],\n",
       "         [3.4630e-02, 2.9351e-02, 8.4456e-01, 8.2610e-01, 4.6809e-01,\n",
       "          2.1871e-02, 7.7769e-01, 7.9522e-01, 5.6011e-01, 4.9945e-01],\n",
       "         [3.0370e-01, 8.2273e-01, 1.8249e-01, 9.1724e-01, 9.2694e-01,\n",
       "          3.0129e-01, 1.3595e-01, 9.9920e-02, 4.3132e-01, 7.1664e-01],\n",
       "         [9.5950e-01, 7.6012e-01, 9.6718e-01, 4.1719e-01, 8.1189e-01,\n",
       "          1.0792e-01, 8.9838e-01, 7.6085e-01, 9.0564e-01, 7.4723e-01],\n",
       "         [5.1736e-01, 9.4504e-01, 8.8675e-01, 1.6468e-01, 9.6169e-01,\n",
       "          4.4750e-01, 4.6954e-01, 5.8987e-01, 2.7195e-01, 2.0267e-01]],\n",
       "\n",
       "        [[2.4911e-01, 8.1615e-01, 9.2427e-01, 9.0217e-02, 8.2095e-01,\n",
       "          8.2212e-01, 1.0312e-01, 3.9410e-02, 2.7397e-01, 5.0727e-01],\n",
       "         [7.7074e-01, 6.4907e-01, 1.3329e-02, 1.9033e-01, 4.8700e-01,\n",
       "          9.2672e-01, 1.7532e-01, 7.0882e-01, 2.7939e-01, 7.2674e-02],\n",
       "         [2.8143e-01, 6.7156e-01, 2.3583e-01, 2.4581e-01, 7.7967e-01,\n",
       "          6.1529e-01, 1.8656e-01, 9.4944e-01, 6.0927e-01, 1.7846e-01],\n",
       "         [9.7981e-01, 1.9135e-02, 1.3618e-01, 8.7827e-01, 2.4154e-02,\n",
       "          9.5728e-02, 7.3748e-01, 7.9775e-01, 6.1598e-01, 5.2195e-01],\n",
       "         [2.9347e-01, 5.2603e-01, 9.6897e-01, 4.7715e-01, 5.5344e-01,\n",
       "          9.9814e-01, 3.2948e-01, 9.2331e-01, 4.6876e-01, 1.8750e-01],\n",
       "         [8.3425e-01, 1.4656e-01, 8.3633e-01, 1.3641e-01, 3.6899e-03,\n",
       "          7.5642e-01, 1.7442e-01, 5.6589e-01, 5.2286e-01, 9.7615e-03],\n",
       "         [7.1622e-01, 3.5219e-01, 7.6182e-01, 8.5874e-01, 6.2248e-01,\n",
       "          4.2836e-01, 8.7135e-02, 1.5270e-01, 8.4256e-01, 6.2911e-01],\n",
       "         [7.1698e-01, 7.7042e-01, 6.1297e-01, 2.1126e-02, 7.7048e-01,\n",
       "          9.0033e-01, 7.1375e-01, 7.8029e-01, 6.2511e-01, 1.4814e-01],\n",
       "         [7.0762e-01, 8.5596e-01, 6.4313e-01, 1.1401e-01, 3.1785e-02,\n",
       "          3.6517e-01, 4.5569e-01, 9.8277e-01, 5.7295e-01, 6.3789e-01],\n",
       "         [8.9601e-01, 2.0796e-01, 7.3787e-01, 3.0272e-01, 8.8468e-01,\n",
       "          3.1882e-01, 1.9448e-01, 1.8065e-01, 1.3597e-01, 8.6648e-01]],\n",
       "\n",
       "        [[7.9946e-01, 6.6752e-01, 1.9028e-01, 2.5789e-01, 4.7998e-01,\n",
       "          2.1552e-01, 2.3504e-01, 8.7776e-02, 2.8417e-01, 6.0046e-01],\n",
       "         [4.2848e-01, 1.5256e-01, 5.6946e-01, 8.1215e-01, 9.1828e-01,\n",
       "          1.4883e-01, 1.1986e-01, 4.1301e-01, 6.2631e-01, 6.7074e-01],\n",
       "         [8.0295e-01, 4.4277e-02, 9.5358e-01, 7.4692e-01, 7.2076e-01,\n",
       "          8.7099e-01, 3.6383e-01, 1.4980e-01, 6.4710e-01, 6.1025e-01],\n",
       "         [4.4279e-01, 4.1724e-01, 3.3781e-01, 2.6791e-01, 1.0405e-01,\n",
       "          2.0327e-01, 3.3602e-01, 6.9537e-01, 9.2011e-01, 8.9784e-01],\n",
       "         [3.9408e-01, 3.8437e-01, 4.5705e-03, 4.5090e-01, 9.4541e-01,\n",
       "          6.5590e-01, 8.5214e-01, 8.6250e-01, 1.7698e-01, 1.9507e-02],\n",
       "         [3.9132e-02, 6.8383e-01, 5.3056e-01, 5.6970e-01, 9.4423e-01,\n",
       "          4.5541e-01, 3.2502e-01, 9.6017e-01, 2.7112e-01, 2.9591e-01],\n",
       "         [6.4477e-01, 4.7638e-01, 6.2106e-01, 6.7598e-01, 9.9929e-01,\n",
       "          9.5062e-01, 4.8664e-01, 8.8829e-02, 6.8810e-02, 4.8620e-01],\n",
       "         [1.0348e-01, 7.3565e-01, 6.2434e-02, 2.0657e-01, 1.3473e-01,\n",
       "          2.5082e-03, 1.6764e-01, 5.1721e-01, 2.4314e-01, 5.1337e-01],\n",
       "         [7.7166e-01, 2.9120e-01, 8.1777e-01, 3.8056e-02, 5.0364e-01,\n",
       "          5.8164e-03, 7.3896e-03, 9.4453e-01, 7.9062e-01, 2.1950e-01],\n",
       "         [3.4040e-01, 5.6522e-01, 8.9410e-01, 1.7029e-01, 9.6141e-01,\n",
       "          7.5026e-01, 4.2832e-01, 1.5835e-02, 2.3527e-01, 4.2294e-01]],\n",
       "\n",
       "        [[9.8175e-01, 2.6702e-01, 2.2264e-01, 5.5324e-01, 9.1651e-01,\n",
       "          7.0165e-01, 4.5440e-02, 6.0707e-01, 2.0495e-01, 7.4091e-02],\n",
       "         [3.0239e-01, 2.7915e-01, 8.0909e-01, 4.5944e-01, 3.6888e-01,\n",
       "          4.1498e-01, 4.8546e-01, 2.7711e-01, 3.1863e-01, 9.6594e-01],\n",
       "         [9.9399e-01, 5.5191e-01, 4.5246e-01, 6.3838e-01, 9.1528e-01,\n",
       "          6.7064e-01, 9.8403e-01, 9.2916e-01, 7.8577e-01, 3.0191e-01],\n",
       "         [3.4908e-01, 2.3975e-01, 8.9887e-01, 4.4174e-01, 8.6350e-01,\n",
       "          9.1448e-01, 2.6088e-02, 7.0195e-01, 5.9537e-01, 1.2574e-01],\n",
       "         [6.8613e-01, 1.9475e-01, 5.8828e-01, 1.5667e-01, 8.0002e-01,\n",
       "          2.9331e-01, 1.5738e-01, 4.3039e-01, 8.5997e-01, 7.7153e-01],\n",
       "         [5.1386e-01, 6.8269e-01, 8.7474e-01, 9.1874e-01, 5.6198e-01,\n",
       "          6.9096e-01, 7.1224e-01, 3.3915e-01, 6.5258e-01, 9.2333e-01],\n",
       "         [6.8809e-02, 3.1097e-01, 1.8683e-01, 5.8523e-01, 7.4278e-01,\n",
       "          5.2345e-01, 3.4147e-01, 1.6451e-01, 3.0863e-01, 9.3596e-01],\n",
       "         [1.3303e-01, 3.3768e-01, 2.6017e-01, 2.7206e-01, 2.7924e-01,\n",
       "          5.5347e-01, 5.3282e-01, 6.4366e-01, 1.4843e-01, 8.3236e-01],\n",
       "         [3.0769e-01, 6.4857e-01, 7.6119e-01, 5.5689e-01, 9.5648e-01,\n",
       "          2.6688e-01, 2.6738e-01, 3.2365e-01, 7.9893e-01, 7.5929e-02],\n",
       "         [4.2880e-02, 1.5405e-01, 2.5762e-01, 1.3725e-01, 3.8744e-01,\n",
       "          9.3942e-01, 2.1301e-01, 8.4871e-01, 5.4055e-01, 3.6103e-01]],\n",
       "\n",
       "        [[8.5786e-01, 9.2562e-01, 7.5002e-01, 3.9492e-01, 1.7762e-01,\n",
       "          4.9286e-02, 2.1448e-01, 4.9989e-01, 4.9116e-01, 1.6498e-01],\n",
       "         [3.6363e-02, 2.6852e-01, 8.5376e-01, 9.1242e-02, 8.1816e-01,\n",
       "          8.0057e-02, 7.4823e-01, 1.9779e-01, 7.4218e-01, 9.2568e-01],\n",
       "         [7.1951e-01, 7.4043e-02, 4.4194e-01, 8.0397e-01, 1.5597e-01,\n",
       "          1.0525e-01, 1.6664e-01, 3.2072e-01, 7.8228e-01, 2.1241e-01],\n",
       "         [5.6879e-01, 7.5466e-01, 9.7147e-01, 3.0169e-01, 5.7721e-01,\n",
       "          1.0382e-01, 8.6872e-01, 5.4129e-01, 9.2281e-01, 4.1654e-01],\n",
       "         [4.0283e-01, 8.5187e-01, 6.6352e-02, 4.1440e-01, 4.2395e-01,\n",
       "          8.8801e-01, 8.2710e-01, 4.8016e-01, 5.8131e-01, 9.5743e-01],\n",
       "         [9.2970e-01, 9.6135e-01, 7.5571e-01, 4.0877e-01, 6.4971e-01,\n",
       "          5.3017e-01, 7.3067e-01, 7.8146e-01, 9.0967e-01, 3.0770e-01],\n",
       "         [3.1727e-02, 9.9526e-01, 2.0250e-01, 6.7414e-01, 1.1634e-01,\n",
       "          7.6753e-01, 5.2350e-01, 1.1705e-01, 7.7424e-01, 6.8829e-01],\n",
       "         [8.6021e-01, 6.2446e-01, 7.4760e-01, 8.3398e-02, 7.6520e-01,\n",
       "          1.0137e-01, 2.9444e-01, 1.2520e-02, 8.9405e-01, 6.9251e-01],\n",
       "         [2.0237e-01, 7.8806e-01, 9.2260e-03, 9.3485e-01, 8.1050e-01,\n",
       "          7.7005e-01, 2.2429e-01, 5.8933e-01, 2.3095e-01, 2.4214e-01],\n",
       "         [9.5512e-01, 3.6572e-01, 1.9748e-01, 4.8819e-01, 6.1147e-01,\n",
       "          7.9259e-01, 3.5960e-01, 8.2629e-01, 9.4543e-02, 2.9583e-01]],\n",
       "\n",
       "        [[3.3610e-01, 1.1523e-01, 2.7454e-04, 3.6534e-01, 8.4862e-02,\n",
       "          7.4982e-01, 8.8772e-01, 5.8668e-01, 8.4713e-01, 4.5239e-01],\n",
       "         [6.2944e-01, 5.9313e-01, 5.9029e-01, 1.1438e-01, 8.5331e-02,\n",
       "          6.5380e-01, 8.6707e-01, 9.8091e-01, 2.1757e-02, 9.4875e-01],\n",
       "         [7.0783e-01, 4.4849e-01, 5.7344e-01, 9.0650e-01, 6.3022e-01,\n",
       "          2.4407e-01, 4.5399e-01, 2.7548e-02, 5.2672e-02, 2.2375e-02],\n",
       "         [8.6254e-01, 5.7696e-01, 6.4894e-01, 4.4628e-01, 1.9587e-01,\n",
       "          3.5212e-01, 9.1189e-01, 8.9449e-01, 7.0139e-01, 7.8277e-01],\n",
       "         [4.4066e-01, 1.2293e-02, 3.1285e-01, 3.4725e-01, 4.3154e-01,\n",
       "          7.1272e-01, 9.9315e-01, 2.4761e-01, 3.2355e-02, 8.6398e-01],\n",
       "         [4.5498e-01, 2.4095e-01, 5.9864e-02, 4.0582e-01, 4.6820e-01,\n",
       "          6.5344e-01, 8.2432e-01, 1.9074e-01, 2.3227e-01, 8.2859e-01],\n",
       "         [5.9136e-01, 4.1631e-01, 6.1844e-01, 6.3717e-01, 2.3356e-01,\n",
       "          5.2099e-01, 5.3211e-01, 1.3241e-01, 6.4826e-01, 4.5150e-01],\n",
       "         [6.2332e-02, 6.7354e-01, 5.1978e-01, 8.3762e-01, 1.1445e-01,\n",
       "          6.1370e-01, 7.3439e-01, 2.4647e-01, 7.5005e-01, 5.2743e-01],\n",
       "         [5.1809e-01, 4.3970e-01, 6.9863e-01, 9.7087e-02, 9.1021e-01,\n",
       "          5.1900e-02, 3.9757e-01, 2.9834e-01, 4.4045e-01, 1.2863e-01],\n",
       "         [9.9612e-01, 9.2769e-01, 8.4658e-01, 5.6947e-01, 9.9481e-01,\n",
       "          2.0631e-01, 5.7333e-01, 5.3872e-01, 7.4215e-01, 7.4966e-01]],\n",
       "\n",
       "        [[2.1765e-01, 4.0460e-01, 2.4927e-02, 1.9502e-01, 8.6411e-01,\n",
       "          3.3690e-01, 7.4195e-03, 3.5810e-01, 4.5643e-01, 7.1149e-01],\n",
       "         [2.7464e-01, 9.3466e-01, 5.2082e-02, 8.8216e-01, 8.1141e-01,\n",
       "          8.4984e-02, 7.0018e-01, 5.3006e-01, 4.5768e-01, 6.1148e-01],\n",
       "         [1.3697e-01, 7.8257e-01, 5.5064e-01, 4.7599e-01, 8.9816e-01,\n",
       "          4.3692e-01, 2.5668e-02, 1.4955e-01, 9.9171e-01, 6.9946e-01],\n",
       "         [1.4119e-01, 4.9586e-01, 1.6304e-01, 8.1258e-01, 3.5191e-01,\n",
       "          6.1256e-01, 2.7691e-01, 4.0366e-01, 7.5248e-01, 1.8229e-01],\n",
       "         [9.2504e-02, 4.0923e-01, 5.6396e-01, 3.3508e-02, 1.6527e-01,\n",
       "          1.3280e-01, 8.8635e-01, 5.3772e-01, 3.5683e-01, 7.8389e-01],\n",
       "         [7.1758e-02, 3.5438e-01, 3.2842e-01, 3.3402e-01, 7.9615e-01,\n",
       "          3.3304e-01, 8.7596e-01, 3.3781e-01, 2.6853e-01, 2.3444e-01],\n",
       "         [6.8066e-01, 6.0788e-01, 2.0485e-01, 9.1665e-01, 9.5050e-01,\n",
       "          6.5195e-01, 6.5871e-01, 5.0839e-01, 4.5869e-01, 1.3330e-02],\n",
       "         [5.9114e-01, 8.8228e-01, 8.0641e-01, 3.2399e-01, 2.8987e-01,\n",
       "          2.0025e-01, 8.5277e-01, 3.5573e-01, 6.2750e-01, 9.6896e-01],\n",
       "         [9.9000e-01, 6.9571e-01, 8.3293e-01, 2.0831e-01, 6.2294e-01,\n",
       "          3.8596e-01, 2.7585e-02, 3.2637e-01, 8.1436e-01, 3.3561e-01],\n",
       "         [5.9508e-01, 8.7047e-01, 8.5394e-01, 8.3498e-01, 8.7448e-01,\n",
       "          4.5867e-01, 1.6026e-01, 6.5048e-01, 7.1222e-01, 4.0067e-01]],\n",
       "\n",
       "        [[8.4079e-01, 2.1494e-01, 3.0228e-01, 2.2889e-01, 1.9512e-01,\n",
       "          4.7892e-01, 8.4137e-01, 4.0277e-01, 4.6679e-01, 7.6053e-01],\n",
       "         [9.8987e-01, 1.2144e-03, 5.0447e-01, 3.2636e-01, 5.2471e-01,\n",
       "          5.9408e-01, 3.0978e-01, 5.6722e-01, 2.0088e-01, 7.3491e-01],\n",
       "         [5.8023e-01, 1.5427e-01, 6.4939e-01, 7.9564e-02, 4.7985e-01,\n",
       "          9.1020e-01, 5.5095e-01, 6.0887e-01, 3.2240e-01, 9.8929e-01],\n",
       "         [8.6875e-01, 1.3513e-01, 5.9500e-01, 6.1107e-01, 9.3307e-01,\n",
       "          3.5193e-01, 6.4953e-02, 7.1776e-01, 2.8904e-02, 3.7070e-01],\n",
       "         [4.8894e-01, 6.2358e-01, 4.7859e-01, 5.2855e-01, 3.8239e-01,\n",
       "          4.2318e-01, 8.2029e-01, 3.9080e-01, 6.9893e-01, 5.9356e-01],\n",
       "         [7.2369e-01, 9.7593e-01, 7.3475e-01, 1.7770e-01, 7.3014e-01,\n",
       "          2.7542e-01, 6.5585e-01, 6.3104e-01, 4.8619e-01, 1.4141e-01],\n",
       "         [9.5933e-01, 3.2149e-01, 6.0070e-01, 7.8039e-01, 7.7995e-01,\n",
       "          9.4179e-01, 1.7051e-01, 8.7125e-01, 6.4680e-01, 7.4385e-01],\n",
       "         [8.0758e-01, 4.8505e-01, 8.2740e-01, 4.3078e-01, 8.9841e-01,\n",
       "          7.1161e-01, 6.9243e-01, 2.2800e-01, 6.7764e-01, 8.0414e-01],\n",
       "         [7.9896e-01, 7.3155e-01, 4.9151e-01, 1.9996e-02, 2.8815e-01,\n",
       "          8.3557e-01, 2.9121e-01, 8.0571e-01, 8.5207e-01, 5.3635e-01],\n",
       "         [9.4418e-01, 9.8823e-01, 1.5816e-01, 3.8686e-01, 1.3050e-01,\n",
       "          2.6319e-01, 4.6245e-01, 8.8256e-01, 6.9836e-02, 8.6139e-01]],\n",
       "\n",
       "        [[4.9803e-01, 5.3530e-01, 2.1721e-01, 2.5144e-01, 4.9677e-01,\n",
       "          5.0992e-01, 7.6891e-01, 6.4785e-01, 3.2437e-01, 2.0043e-01],\n",
       "         [3.2746e-01, 8.3173e-01, 1.6349e-01, 1.8744e-01, 3.4289e-02,\n",
       "          2.3026e-02, 3.9748e-01, 1.9730e-01, 9.6234e-01, 9.8395e-01],\n",
       "         [7.7704e-01, 1.2868e-01, 6.2550e-01, 2.8765e-01, 4.5448e-01,\n",
       "          9.0427e-01, 9.5035e-01, 3.6628e-01, 3.9946e-01, 1.7459e-01],\n",
       "         [7.8681e-01, 6.1500e-02, 2.8466e-01, 8.3886e-01, 3.9503e-01,\n",
       "          7.3684e-01, 8.0148e-01, 9.1031e-02, 3.0311e-01, 7.4831e-01],\n",
       "         [9.6714e-02, 5.6151e-01, 2.8039e-01, 2.9912e-01, 2.5021e-01,\n",
       "          6.7198e-01, 8.4317e-01, 6.9090e-01, 1.1113e-01, 7.3087e-01],\n",
       "         [6.5337e-01, 6.9582e-01, 7.8989e-01, 6.3511e-01, 6.3057e-01,\n",
       "          4.4835e-01, 5.9661e-01, 8.7909e-01, 9.8029e-01, 4.3788e-02],\n",
       "         [9.9979e-02, 5.3870e-01, 2.2943e-01, 4.9625e-01, 7.7131e-01,\n",
       "          8.5300e-01, 5.8425e-01, 3.1821e-01, 8.0034e-01, 8.2046e-01],\n",
       "         [6.1153e-01, 8.8704e-01, 9.8561e-01, 1.1117e-02, 2.4636e-01,\n",
       "          7.3898e-01, 7.4832e-01, 2.0850e-01, 1.7298e-01, 6.4933e-01],\n",
       "         [5.3864e-01, 6.9674e-02, 3.6805e-01, 4.7065e-01, 1.6020e-01,\n",
       "          8.7726e-01, 1.5815e-01, 1.2539e-01, 3.4071e-02, 1.7115e-01],\n",
       "         [2.3919e-01, 1.5326e-01, 3.8652e-01, 7.0573e-01, 8.8972e-01,\n",
       "          7.2133e-01, 9.5910e-01, 6.6736e-01, 4.8597e-01, 8.8458e-01]]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor_2 = torch.rand(10, 10, 10)\n",
    "random_tensor_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor_2.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([224, 224, 3]), torch.Size([224, 224, 3]), 3)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_image_size_tensor = torch.rand(size=(224, 224, 3))\n",
    "# height, width, color channels(rgb)\n",
    "random_image_size_tensor.shape, random_image_size_tensor.size(), random_image_size_tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### zeros and ones tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a tensor of all zeros\n",
    "zeros = torch.zeros(size = (3, 4))\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros * random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones = torch.ones(3, 4)\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5273, 0.3559, 0.3121, 0.6394],\n",
       "        [0.0758, 0.1926, 0.3885, 0.8590],\n",
       "        [0.7229, 0.1401, 0.0044, 0.9996]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones * random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.3260, 0.6886, 0.7050, 2.4981])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a range of tensor and tensors-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_to_ten = torch.arange(1, 11)\n",
    "one_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,  77, 154, 231, 308, 385, 462, 539, 616, 693, 770, 847, 924])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_to_thousand_step_77 = torch.arange(start=0,\n",
    "                                        end =  1000,\n",
    "                                        step= 77                      \n",
    "                                        )\n",
    "zero_to_thousand_step_77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating tensors like\n",
    "ten_zeros = torch.zeros_like(input=one_to_ten)\n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor datatypes\n",
    "\n",
    "- **Note:** Tensor datatypes is one of the 3 big erros you'll run into PyTorch and deep learning\n",
    "1. Tensors not right datatype\n",
    "2. Tensors not right shape\n",
    "3. Tensors not on the right device\n",
    "   1. 如果两个TensorFlow不在一个设备上，一个在CPU上，一个在GPU上\n",
    "\n",
    "### Getting information from tensors(tensor attributes)\n",
    "\n",
    "1. to get datatype from a tensor —— use `tensor.dtype`\n",
    "2. to get shape from a tensor —— use `tensor.shape`\n",
    "3. to get device from a tensor —— use `tensor.device`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor = torch.tensor([1, 2, 3],\n",
    "                               device=\"cuda\", # What device is your tensor on\n",
    "                               dtype=torch.float32, # What datatype is the tensor\n",
    "                               requires_grad=True) # Whether or not to track gradients with this tensor operations\n",
    "float_32_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor = float_32_tensor.type(torch.half)\n",
    "float_16_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_mul = float_16_tensor * float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_mul.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8973, 0.6691, 0.2112, 0.5859],\n",
       "        [0.2440, 0.2204, 0.4296, 0.7690],\n",
       "        [0.3252, 0.4518, 0.0121, 0.4199]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a tensor\n",
    "some_tensor = torch.rand(3, 4)\n",
    "some_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8973, 0.6691, 0.2112, 0.5859],\n",
      "        [0.2440, 0.2204, 0.4296, 0.7690],\n",
      "        [0.3252, 0.4518, 0.0121, 0.4199]])\n",
      "DataType of tensor: torch.float32\n",
      "Shape of tensor: torch.Size([3, 4])\n",
      "Device tensor is on: cpu\n"
     ]
    }
   ],
   "source": [
    "# Find out details about some tensor\n",
    "\n",
    "print(some_tensor)\n",
    "print(f\"DataType of tensor: {some_tensor.dtype}\")\n",
    "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
    "print(f\"Device tensor is on: {some_tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating Tensors (tensor operation)\n",
    "\n",
    "Tensor operation include:\n",
    "- 加法\n",
    "- 减法\n",
    "- 乘法\n",
    "- 除法\n",
    "- 矩阵相乘 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a tensor\n",
    "\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "tensor + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-99, -98, -97])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor - 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multiplication\n",
    "\n",
    "tensor * 10\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10, 20, 30])\n",
      "tensor([11, 12, 13])\n"
     ]
    }
   ],
   "source": [
    "print(torch.mul(tensor, 10))\n",
    "print(torch.add(tensor, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix multiplication\n",
    "\n",
    "two main ways of performing multiplication:\n",
    "1. element-wise multiplication\n",
    "2. matrix multiplication\n",
    "\n",
    "There are two main rules that preforming matrix multiplicatoin needs to satisfy:\n",
    "1. The **inner dimensions** must match\n",
    "   1. `(3, 2) @ (3, 2)`报错\n",
    "   2. `(3, 2) @ (2, 3)` 和 `(2, 3) @ (3, 2)`都不会报错\n",
    "2. The resulting matrix has the shape of the **outer dimensions**\n",
    "   1. `(3, 2) @ (2, 3) -> (3, 3)`\n",
    "   2. `(2, 3) @ (3, 2) -> (2, 2)`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
      "Equels: tensor([1, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "# Element wise multiplication\n",
    "\n",
    "print(tensor, \"*\", tensor)\n",
    "print(f\"Equels: {(tensor * tensor)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "value = 0\n",
    "for i in range(len(tensor)):\n",
    "    value += tensor[i] * tensor[i]\n",
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_1 = torch.rand(3, 2)\n",
    "tensor_2 = torch.rand(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 1 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.6835, 0.4468, 0.4217],\n",
       "        [0.7926, 0.5044, 0.5998],\n",
       "        [0.4488, 0.3179, 0.0797]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "torch.matmul(tensor_1, tensor_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One of the most common errors in dl: shape errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]), torch.Size([3, 2]))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_A = torch.tensor([[1, 2],\n",
    "                         [3, 4],\n",
    "                         [5, 6]])\n",
    "tensor_B = torch.tensor([[7, 8],\n",
    "                         [9, 10],\n",
    "                         [11, 12]])\n",
    "\n",
    "# torch.mm()\n",
    "tensor_A.shape, tensor_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[101], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_B\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "torch.mm(tensor_A, tensor_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用transpose\n",
    "\n",
    "- 转置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  9, 11],\n",
       "        [ 8, 10, 12]])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .T表示transpose\n",
    "\n",
    "tensor_B.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 23,  29,  35],\n",
       "        [ 53,  67,  81],\n",
       "        [ 83, 105, 127]])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(tensor_A, tensor_B.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor_A的形状是torch.Size([3, 2]), tensor_B的形状是torch.Size([3, 2])\n",
      "B矩阵转置之后，tensor_A的形状是torch.Size([3, 2])， tensor_B的形状是torch.Size([2, 3])\n",
      "Multiplying torch.Size([3, 2]) @ torch.Size([2, 3])\n",
      "Output: tensor([[ 23,  29,  35],\n",
      "        [ 53,  67,  81],\n",
      "        [ 83, 105, 127]])\n",
      "Output's Shape: torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "# 当B转置之后， 两个矩阵就可以实现矩阵乘法\n",
    "\n",
    "print(f\"tensor_A的形状是{tensor_A.shape}, tensor_B的形状是{tensor_B.shape}\")\n",
    "print(f\"B矩阵转置之后，tensor_A的形状是{tensor_A.shape}， tensor_B的形状是{tensor_B.T.shape}\")\n",
    "print(f\"Multiplying {tensor_A.shape} @ {tensor_B.T.shape}\")\n",
    "print(f\"Output: {torch.mm(tensor_A, tensor_B.T)}\")\n",
    "print(f\"Output's Shape: {torch.mm(tensor_A, tensor_B.T).shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the max, min, mean, sum, etc(tensor aggregation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90]), torch.int64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "x = torch.arange(0, 100, 10)\n",
    "x, x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the min\n",
    "x.min(), torch.min(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(90), tensor(90))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the max\n",
    "x.max(), torch.max(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Find the mean\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long"
     ]
    }
   ],
   "source": [
    "# Find the mean\n",
    "# 输入的张量元素必须是float32\n",
    "\n",
    "x.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(45.)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.type(torch.float32).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(450), tensor(450))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the sum\n",
    "\n",
    "torch.sum(x), x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\n",
      "Version: 2.4.1\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3\n",
      "Location: f:\\.conda\\d2l-zh\\lib\\site-packages\n",
      "Requires: filelock, fsspec, jinja2, networkx, sympy, typing-extensions\n",
      "Required-by: torchaudio, torchvision\n"
     ]
    }
   ],
   "source": [
    "!pip show torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: d2l\n",
      "Version: 1.0.3\n",
      "Summary: Dive into Deep Learning\n",
      "Home-page: https://d2l.ai\n",
      "Author: D2L Developers\n",
      "Author-email: d2l.devs@gmail.com\n",
      "License: MIT-0\n",
      "Location: f:\\.conda\\d2l-zh\\lib\\site-packages\n",
      "Requires: jupyter, matplotlib, matplotlib-inline, numpy, pandas, requests, scipy\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "发现了一个区别函数和属性的方法：\n",
    "- 在提示中\n",
    "- 属性前面是一个黑板擦\n",
    "- 方法前面是一个立方体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3234, 0.5551],\n",
       "        [0.4348, 0.6957],\n",
       "        [0.9572, 0.0127],\n",
       "        [0.9403, 0.0761],\n",
       "        [0.1717, 0.8251],\n",
       "        [0.2687, 0.9575],\n",
       "        [0.6368, 0.8102],\n",
       "        [0.6707, 0.2779],\n",
       "        [0.4250, 0.5594],\n",
       "        [0.2983, 0.9217]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_X = torch.rand(size=(10,2))\n",
    "tensor_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 2])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dim=0 表示沿着第0维（行）方向找最小值的索引\n",
    "# 返回每列的最小值所在的行索引\n",
    "# 结果是一个形状为[2]的张量，对应tensor_X的两列\n",
    "tensor_X.argmin(dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping, stacking, squeezing and unsqueezing tensors\n",
    "\n",
    "- Reshaping: 将输入的tensor改变为指定的形状\n",
    "- View: 功能与reshape类似，但是返回的是原张量的视图\n",
    "- Stacking: 将多个张量沿着新的维度堆叠起来\n",
    "- Squeeze: 移出所有大小为1的维度\n",
    "- Unsqueeze: 在指定位置添加一个大小为1的维度\n",
    "- Permute: 改变张量的维度顺序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1, 10, dtype=torch.float32)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3.],\n",
       "         [4., 5., 6.],\n",
       "         [7., 8., 9.]]),\n",
       " torch.Size([9]))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.reshape(3, 3), x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the view\n",
    "z = x.view(1, 9)\n",
    "z, z.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# changing z changes x (because a viwe of z shares the same memory as the original input)\n",
    "z[0][0] = 5\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "        [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "        [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "        [5., 2., 3., 4., 5., 6., 7., 8., 9.]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack tensors on top of each other\n",
    "x_stacked = torch.stack([x, x, x, x])\n",
    "x_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 5., 5., 5.],\n",
       "        [2., 2., 2., 2.],\n",
       "        [3., 3., 3., 3.],\n",
       "        [4., 4., 4., 4.],\n",
       "        [5., 5., 5., 5.],\n",
       "        [6., 6., 6., 6.],\n",
       "        [7., 7., 7., 7.],\n",
       "        [8., 8., 8., 8.],\n",
       "        [9., 9., 9., 9.]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_stacked_1 = torch.stack([x, x, x, x], dim=1)\n",
    "x_stacked_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped = torch.arange(1., 10.)\n",
    "x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped = x_reshaped.reshape(1, 9)\n",
    "x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_reshaped.squeeze(), x_reshaped.squeeze().shape\n",
    "x_squeezed = x_reshaped.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous squeezed target: tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "Previous shape: torch.Size([9])\n",
      "\n",
      "New tensor: tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
      "New shape: torch.Size([1, 9])\n",
      "\n",
      "New tensor: tensor([[1.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [4.],\n",
      "        [5.],\n",
      "        [6.],\n",
      "        [7.],\n",
      "        [8.],\n",
      "        [9.]])\n",
      "New shape: torch.Size([9, 1])\n"
     ]
    }
   ],
   "source": [
    "# torch.unsqueezed() -- adda a single dimension to a target tensor at a specific dim\n",
    "\n",
    "print(f\"Previous squeezed target: {x_squeezed}\")\n",
    "print(f\"Previous shape: {x_squeezed.shape}\")\n",
    "\n",
    "\n",
    "# add an extra dimension with unsqueeze\n",
    "x_unsqueezed = x_squeezed.unsqueeze(dim=0)\n",
    "print(f\"\\nNew tensor: {x_unsqueezed}\")\n",
    "print(f\"New shape: {x_unsqueezed.shape}\")\n",
    "\n",
    "\n",
    "x_unsqueezed_1 = x_squeezed.unsqueeze(dim=1)\n",
    "print(f\"\\nNew tensor: {x_unsqueezed_1}\")\n",
    "print(f\"New shape: {x_unsqueezed_1.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 5])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.permute - rearranges the dimensions of a target tensor in a specified order\n",
    "x_original =  torch.rand(size=(3, 4, 5))\n",
    "x_original.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 4])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用permute操作\n",
    "# 将原来第2维度的放在新的第0维度\n",
    "# 原来第0维度放在新的第1维度\n",
    "# 原来第1维度放在新的第2维度\n",
    "x_permuted = x_original.permute(2, 0, 1)\n",
    "x_permuted.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing(selecting data from tensors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]]),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1, 10).reshape(shape=(1, 3, 3))\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3]), tensor([1, 2, 3]))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][0], x[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4, 5, 6]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 5, 8]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index on x to return 9\n",
    "\n",
    "x[0, 2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 6, 9]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index on x to return 3 6 9\n",
    "x[:, :, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interact with numpy\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 3., 4., 5., 6., 7., 8., 9.])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "array = np.arange(1., 10.)\n",
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.], dtype=torch.float64)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.from_numpy(array)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7., 8., 9.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.], dtype=torch.float64))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(1.0, 8.0).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.], dtype=torch.float64))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change the value of array, see what will do this to tensor\n",
    "array = array + 1\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensor to numpy\n",
    "tensor = torch.ones(7)\n",
    "numpy_tensor = tensor.numpy()\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2., 2., 2., 2., 2., 2., 2.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = tensor + 1\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproducibility(trying to take random out of random)\n",
    "\n",
    "In short how a neural network learns:\n",
    "\n",
    "`start with random numebrs -> tensor operations -> update random numbers to try and make them better representations of the data -> again -> again -> again`\n",
    "\n",
    "To reduce the randomness in neural networks and PyTorch comes the concept of a **random seed**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l-zh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
