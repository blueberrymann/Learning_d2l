{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ![神经元图片](/attachments/LinearRegressionNeural.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 衡量预估质量\n",
    "\n",
    "- 比较真实值和估计值，例如房屋售价和预估价格\n",
    "- 假设$y$是真实值，$\\hat{y}$是预估值，我们可以通过平方损失来衡量，公式如下$$y=\\frac{1}{2}(y - \\hat{y})^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练数据\n",
    "\n",
    "- 训练数据：收集一定的数据点来决定参数值（权重和偏差），通常是越多越好\n",
    "- 假设我们有n个样本，记$$\\textbf{X} = [\\textbf{x}_1, \\textbf{x}_2, \\textbf{x}_3, ..., \\textbf{x}_n]^T, y = [y_1, y_2, y_3, ..., y_n]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参数学习\n",
    "\n",
    "- 训练损失$$l(\\textbf{X}, \\textbf{y}, \\textbf{w}, b)=\\frac{1}{2n}\\sum^n_{i=1}(y_i-<\\textbf{x},\\textbf{w}> - b)^2=\\frac{1}{2n}||\\textbf{y}-\\textbf{Xw}-b||^2$$\n",
    "- 最小化损失来学习参数，我们通过调整$\\textbf{w}^*$ $\\textbf{b}^*$，使得损失能够最小化$$\\textbf{w}^*,\\textbf{b}^*=argmin_{w,b}l(\\textbf{X}, \\textbf{y}, \\textbf{w}, b)$$\n",
    "- 最后求出线性回归的显式解（具体求解过程详见ipad笔记）$$w^* = (X^TX)^{-1}X^Ty$$\n",
    "\n",
    "## 总结\n",
    "\n",
    "- 线性回归是对n维输入的加权加和，外加偏差\n",
    "- 使用平方损失来表示真实值和预测值之间的误差\n",
    "- 线性回归有显式解\n",
    "- 线性回归可以看做单层神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
